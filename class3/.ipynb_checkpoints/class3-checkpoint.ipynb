{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCMC Review: can anyone say what it is NOT?\n",
    "\n",
    "(a) a method to estimate the posterior\n",
    "\n",
    "(b) a method that relies on estimating the marginal likelihood\n",
    "\n",
    "(c) a method that directly samples from the posterior distribution\n",
    "\n",
    "(d) a method that needs a likelihood and prior\n",
    "\n",
    "## Hierarchical Bayes\n",
    "\n",
    "Bayes about two things for our purposes: \n",
    "\n",
    "Parameter estimation: here, we want the posterior of parameters given the data, assuming a type of model of e.g., learning. When we do this, the parameters are nested within subjects that are themselves nested within a population.\n",
    "\n",
    "Model fitting: Sometimes we marginalize over these parameters. This is the case in model comparison, where a bayes factor is a likelihood ratio of $\\frac{p(data | model_{RL})}{p(data | model_{WSLS})}$.\n",
    "\n",
    "We can do these simultaneously in hierarchical bayes modeling. \n",
    "\n",
    "## Load in and clean data before we start modelling it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paulsharp/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (0,63,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "#load  in data and just consider columsn of importance for analysis\n",
    "df_task=pd.read_csv('task.csv')\n",
    "df_task_r=df_task[['Participant Public ID','display','forced_choice','Response','image2','test_image1', 'test_image2','test_image1_value', \n",
    "                   'test_image2_value','image_query2', 'image_query1']]\n",
    "df_task_r=df_task_r.replace('response_text_entry','query_internal_probability') \n",
    "\n",
    "# Define best-action dictionary for present design\n",
    "# best action per condition (6 conditions)\n",
    "best_answer_key={'rare_threat_1': [[0, 'Pinecone 1.jpg'], [1, 'Pumpkin 1.jpg']], \n",
    "                 'rare_threat_2': [[0, 'Keyboard 3.jpg'], [1, 'Office supplies 2.jpg']],\n",
    "                 'common_threat_1': [[0, 'Fire hydrant 1.jpg'], [1, 'Fence 2.jpg']],\n",
    "                 'common_threat_2': [[0, 'Bricks 1.jpg'], [1, 'Barrels 1.jpg']],\n",
    "                 'neutral_1': [[0, 'Snow 3.jpg'], [1, 'Skyscraper 1.jpg']],\n",
    "                 'neutral_2': [[0, 'Clean 1.jpg'], [1, 'Cotton swabs 3.jpg']]}\n",
    "\n",
    "#best answers per condition: lists\n",
    "rt1=[]\n",
    "rt2=[]\n",
    "ct1=[]\n",
    "ct2=[]\n",
    "n1=[]\n",
    "n2=[]\n",
    "\n",
    "tally=0\n",
    "invalid_scores={'NaN'}\n",
    "counter=0\n",
    "conditions=[]\n",
    "start_new_test_set=0\n",
    "start_new_subject=0\n",
    "best_action_tally=0\n",
    "condition_counter=0\n",
    "sub_counter=0\n",
    "current_subject=1\n",
    "\n",
    "#subject specific data\n",
    "rt_sub=[]\n",
    "ct_sub=[]\n",
    "neut_sub=[]\n",
    "current_choice_data=[]\n",
    "choice_data_3d=np.zeros((13,3,40)) #to be populated below\n",
    "\n",
    "for row,data in df_task_r.iterrows():\n",
    "    \n",
    "    if str(df_task_r['display'][row]).startswith('test'):\n",
    "        \n",
    "        if counter==0:\n",
    "            conditions.append(df_task_r['display'][row][5:])\n",
    "            condition_info=best_answer_key[conditions[counter]]\n",
    "            new_condition=0\n",
    "            counter+=1\n",
    "            \n",
    "\n",
    "        elif df_task_r['display'][row][5:]!=conditions[counter-1]:\n",
    "                    conditions.append(df_task_r['display'][row][5:])\n",
    "                    condition_info=best_answer_key[conditions[counter]]\n",
    "                    if conditions[counter-1]=='rare_threat_1':\n",
    "                        rt1.append(best_action_tally)\n",
    "                        rt_sub.append(current_choice_data)\n",
    "\n",
    "                    elif conditions[counter-1]=='rare_threat_2':\n",
    "                        rt2.append(best_action_tally)\n",
    "                        rt_sub.append(current_choice_data)\n",
    "\n",
    "                    elif conditions[counter-1]=='common_threat_1':\n",
    "                        ct1.append(best_action_tally)\n",
    "                        ct_sub.append(current_choice_data)\n",
    "\n",
    "                    elif conditions[counter-1]=='common_threat_2':\n",
    "                        ct2.append(best_action_tally)\n",
    "                        ct_sub.append(current_choice_data)\n",
    "\n",
    "                    elif conditions[counter-1]=='neutral_1':\n",
    "                        n1.append(best_action_tally)\n",
    "                        neut_sub.append(current_choice_data)\n",
    "\n",
    "                    elif conditions[counter-1]=='neutral_2':\n",
    "                        n2.append(best_action_tally)\n",
    "                        neut_sub.append(current_choice_data)\n",
    "                    counter+=1\n",
    "                    best_action_tally=0\n",
    "                    current_choice_data=[]\n",
    "                    condition_counter+=1\n",
    "                    #after 6 blocks, new subject\n",
    "                    if condition_counter>5:\n",
    "                        current_subject+=1\n",
    "                        neut_sub=neut_sub[0]+neut_sub[1]\n",
    "                        if len(neut_sub)<40:\n",
    "                            neut_sub=[int(x) for x in neut_sub+np.zeros(40-len(neut_sub)).tolist()]\n",
    "             \n",
    "                            \n",
    "                        rt_sub=rt_sub[0]+rt_sub[1]\n",
    "                        if len(rt_sub)<40:\n",
    "                            rt_sub=[int(x) for x in rt_sub+np.zeros(40-len(rt_sub)).tolist()]\n",
    "                      \n",
    "                        ct_sub=ct_sub[0]+ct_sub[1]\n",
    "                        if len(ct_sub)<40:\n",
    "                            ct_sub=[int(x) for x in ct_sub+np.zeros(40-len(ct_sub)).tolist()]\n",
    "                        \n",
    "                        choice_data_3d[sub_counter,0]=neut_sub\n",
    "                        choice_data_3d[sub_counter,1]=ct_sub\n",
    "                        choice_data_3d[sub_counter,2]=rt_sub\n",
    "                        sub_counter+=1                                               \n",
    "                        condition_counter=0\n",
    "                        rt_sub=[]\n",
    "                        ct_sub=[]\n",
    "                        neut_sub=[]\n",
    "        \n",
    "        else:\n",
    "            new_condition=0\n",
    "                    \n",
    "        #Get values and convert from strings to floating point\n",
    "        value1=df_task_r['test_image1_value'][row]\n",
    "        if \"p\" in value1:\n",
    "            value1=float(value1[0:2])*0.01\n",
    "        else:\n",
    "            value1=float(value1[1])\n",
    "        value2=df_task_r['test_image2_value'][row]\n",
    "        if \"p\" in value2:\n",
    "            value2=float(value2[0:2])*0.01\n",
    "        else:\n",
    "            value2=float(value2[1])\n",
    "        \n",
    "        if value1>value2:\n",
    "            best_option=df_task_r['test_image1'][row]\n",
    "        else:\n",
    "            best_option=df_task_r['test_image2'][row]\n",
    "        \n",
    "            \n",
    "        #get response and convert to integer\n",
    "        try:\n",
    "            current_response=int(df_task_r['Response'][row])\n",
    "        except:\n",
    "            current_response='missing'\n",
    "                \n",
    "            \n",
    "        \n",
    "        \n",
    "        # determine if participant made best choice\n",
    "        for info_total in condition_info:\n",
    "            for info in info_total:\n",
    "                if best_option == str(info):\n",
    "                    best_action=info_total[0]\n",
    "\n",
    "    #for last subject only       \n",
    "        if row==17254:\n",
    "            ct2.append(best_action_tally)\n",
    "            ct_sub.append(current_choice_data)\n",
    "            neut_sub=neut_sub[0]+neut_sub[1]\n",
    "            if len(neut_sub)<40:\n",
    "                neut_sub=[int(x) for x in neut_sub+np.zeros(40-len(neut_sub)).tolist()]\n",
    "\n",
    "\n",
    "            rt_sub=rt_sub[0]+rt_sub[1]\n",
    "            if len(rt_sub)<40:\n",
    "                rt_sub=[int(x) for x in rt_sub+np.zeros(40-len(rt_sub)).tolist()]\n",
    "\n",
    "            ct_sub=ct_sub[0]+ct_sub[1]\n",
    "            if len(ct_sub)<40:\n",
    "                ct_sub=[int(x) for x in ct_sub+np.zeros(40-len(ct_sub)).tolist()]\n",
    "\n",
    "            choice_data_3d[sub_counter,0]=neut_sub\n",
    "            choice_data_3d[sub_counter,1]=ct_sub\n",
    "            choice_data_3d[sub_counter,2]=rt_sub\n",
    "            sub_counter+=1                                               \n",
    "            condition_counter=0\n",
    "            rt_sub=[]\n",
    "            ct_sub=[]\n",
    "            neut_sub=[]\n",
    "\n",
    "        else:\n",
    "            if current_response==best_action:\n",
    "                best_action_tally+=1\n",
    "                current_choice_data.append(1.0)\n",
    "            elif current_response=='missing':\n",
    "                x='missing'\n",
    "            else:\n",
    "                current_choice_data.append(0.0)\n",
    "                \n",
    "\n",
    "#convert to numpy arrays    \n",
    "rt1=np.array(rt1)\n",
    "rt2=np.array(rt2)\n",
    "ct1=np.array(ct1)\n",
    "ct2=np.array(ct2)\n",
    "n1=np.array(n1)\n",
    "n2=np.array(n2)\n",
    "\n",
    "choice_data_3d = choice_data_3d.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Modelling real data hierarchically: explaining choice data\n",
    "\n",
    "We can take what we've learned using the coin-bias example to model my pilot data. In my experiment, participants chose an action to obtain a reward based off a latent transition matrix they've presumably learned. The hypothesis is that this transition matrix is altered due to experimentally-manipulated features (valence of emotional distractors during learning) and person-specific factors that are not manipulated (level of chronic worry). \n",
    "\n",
    "We can conceive of the generative model of my data in the following way. We'll start from the bottom up. Each individual's decision is either a 1 or 0 (did they select the best-available option or not). The best-available option is the action that maximizes the EV according to a greedy policy (which is fine here given that learning is separated from decision-making; that is, if I've learned I have a 60% chance pressing X will get me to the highest reward, and Y will get me there 40% of the time, I should always choose X). \n",
    "\n",
    "The coin-bias parameter can be thought of as the same parameter determining a subjects' choice. If their bias is 0, it is an index that they're always choosing the worst action. If the bias is 1, they're maximizing performance. In between defines their uncertainty. \n",
    "\n",
    "We use a Bernoulli likelihood to define the **subject-specific** data-generating process to explain their choice data:\n",
    "\n",
    "$Choice_{i,t}$ $\\sim$ Bernoulli$(\\theta_{i,k})$ Indices: i=subjects, t=trials, k=condition, where k(1) = neutral, k(2) = positive and k(3) = negative. \n",
    "\n",
    "Here, subject-level \"coin-biases\" determining choice vary by subject and condition. A subject specific factor, $\\eta_{i}$ reflecting a baseline decision tendency that is modulated by the experimental condition $\\gamma_{k}$.\n",
    "\n",
    "$\\theta_{i,k}\\,= \\begin{cases}\n",
    "    \\text{logistic}\\, (\\eta_{i} + \\gamma_{1}),& \\text{if } k=1\\\\\n",
    "    \\text{logistic}\\,(\\eta_{i} + \\gamma_{2}),& \\text{if } k=2\\\\\n",
    "    \\text{logistic}\\,(\\eta_{i} + \\gamma_{3}),& \\text{if } k=3\\\\\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "$\\gamma_{1}$, $\\gamma_{2}$, and $\\gamma_{3}$ represent the biases for **each condition** **per subject**, where each is drawn from **group-level distribution over condition effects**:\n",
    "\n",
    "$\\gamma_{i,1}$ $\\sim \\mathcal{N}(\\mu_{1},\\sigma_{1,i})$\n",
    "\n",
    "$\\gamma_{i,2}$ $\\sim \\mathcal{N}(\\mu_{2},\\sigma_{2,i})$\n",
    "\n",
    "$\\gamma_{i,3}$ $\\sim \\mathcal{N}(\\mu_{3},\\sigma_{3,i})$\n",
    "\n",
    "We also have a **subject-specific bias** drawn from the population distribution over biases. One can think of this as the tendency to learn well the state transitions in the present task necessary for good performance.\n",
    "\n",
    "$\\eta_i$ $\\sim$ $\\mathcal{N}(\\mu_{i},\\sigma_{i})$\n",
    "\n",
    "\n",
    "Because we do not know *a priori* what the population-level distribution over each effect should be, we also need a prior distribution on these hyper-parameters (e.g., a prior distribution on $\\mu_{3}$). A good **rule for modeling**: if you are trying to estimate a parameter, it needs a prior. If we did not put a prior on the group-effects, the parameters from which individual-level parameters are drawn would remain fixed. \n",
    "\n",
    "Priors over experimental effects at the population level:\n",
    "\n",
    "Mean Prior:\n",
    "$\\mathcal{N}(\\mathcal{M_{condition}},\\sigma_{condition})$\n",
    "Variance Prior:\n",
    "$\\mathcal{Gamma}(\\mathcal{S},\\mathcal{K})$\n",
    "\n",
    "We also have a prior distribution over **subject effects**:\n",
    "\n",
    "Mean prior:\n",
    "$\\mathcal{N}(\\mathcal{M_{population}},\\sigma_{population})$\n",
    "Variance prior:\n",
    "$\\mathcal{Gamma}(\\mathcal{S},\\mathcal{K})$\n",
    "\n",
    "The posterior joint distribution one is trying to estimate is: $p(\\gamma_{1,1}...\\gamma_{subject_i,condition_k},\\mu_{k},\\sigma_{k},\\mu_{i},\\sigma_{i}|data)$\n",
    "\n",
    "Thus we must estimate $(i \\cdot (k + 1_{subjectBaseline}) + 8_{groupLevel})$ parameters, which for the present dataset, is a 60-dimensional distribution!\n",
    "\n",
    "Let's use pyStan to fit my data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build hierarchical model in pyStan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_b680a468874eea7059d7fda23e2af7dd NOW.\n",
      "WARNING:pystan:271 of 4000 iterations ended with a divergence (6.78 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.8 to remove the divergences.\n",
      "WARNING:pystan:2 of 4000 iterations saturated the maximum tree depth of 10 (0.05 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_b680a468874eea7059d7fda23e2af7dd.\n",
      "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
      "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
      "\n",
      "                     mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "mu_neutral           1.86    0.44   4.86   -8.1  -1.51   2.06   5.14  11.03    121   1.01\n",
      "mu_positive         -0.35    0.44   4.87  -10.1  -3.73  -0.12   2.96   8.88    120   1.01\n",
      "mu_negative         -0.46    0.44   4.88 -10.27  -3.94  -0.25   2.79   8.84    121   1.01\n",
      "mu_subject           2.23    0.44   4.93  -7.18  -1.02   2.04   5.67  11.81    126   1.01\n",
      "sigma_neutral        1.06    0.06   0.62    0.2   0.57   0.96   1.43   2.37     97   1.06\n",
      "sigma_positive       1.18    0.05   0.71   0.17   0.65   1.08   1.58   2.84    215   1.02\n",
      "sigma_negative       1.47    0.03    0.6   0.34    1.1   1.45   1.79   2.79    426   1.01\n",
      "sigma_subject        3.59    0.03   0.83   2.29    3.0   3.49   4.05   5.46    862    1.0\n",
      "gamma_neutral[1]     1.08    0.44   4.91  -8.76  -2.37   1.24   4.47  10.33    123   1.01\n",
      "gamma_neutral[2]     1.95    0.45   5.02  -8.08  -1.55   2.16   5.45  11.38    124   1.01\n",
      "gamma_neutral[3]      2.1    0.44    4.9  -7.73  -1.33   2.31   5.33  11.49    121   1.01\n",
      "gamma_neutral[4]     2.28    0.44   4.96  -7.73  -1.09   2.38   5.66  11.83    125   1.01\n",
      "gamma_neutral[5]     0.63    0.45   4.94  -9.15  -2.93   0.79   3.98   9.87    121   1.01\n",
      "gamma_neutral[6]      2.4    0.44   4.95  -7.57   -0.9   2.61   5.67  11.81    126   1.01\n",
      "gamma_neutral[7]      2.2    0.45    5.0  -7.78  -1.28   2.32   5.61  11.67    122   1.01\n",
      "gamma_neutral[8]     2.21    0.44   4.89  -7.54  -1.22   2.37   5.44  11.64    122   1.01\n",
      "gamma_neutral[9]     1.99    0.45    5.0   -7.9  -1.61   2.21    5.4  11.44    126   1.01\n",
      "gamma_neutral[10]    2.23    0.44   4.98  -7.56  -1.24   2.42   5.48  11.66    126   1.01\n",
      "gamma_neutral[11]    1.98    0.44   4.87  -7.89  -1.44   2.24   5.27  11.43    123   1.01\n",
      "gamma_neutral[12]     2.0    0.45   5.04  -8.12  -1.58   2.05   5.53  11.39    123   1.01\n",
      "gamma_neutral[13]    1.25    0.44   4.94  -8.34  -2.15   1.33   4.65  10.51    124   1.01\n",
      "gamma_positive[1]   -0.74    0.44   4.91 -10.61  -4.13   -0.6   2.56   8.59    123   1.01\n",
      "gamma_positive[2]   -0.03    0.45   5.06  -9.71  -3.65   0.06   3.33   9.81    126   1.01\n",
      "gamma_positive[3]   -1.66    0.44   4.95 -11.72  -5.11  -1.46   1.57   7.87    126   1.01\n",
      "gamma_positive[4]    1.03    0.46   5.12  -9.02   -2.5   0.73   4.53  10.85    126   1.01\n",
      "gamma_positive[5]   -0.01    0.45   4.94   -9.8   -3.5   0.16   3.37    9.3    121   1.01\n",
      "gamma_positive[6]   -1.16    0.44   4.87 -10.94  -4.52  -0.94   1.98   8.19    123   1.01\n",
      "gamma_positive[7]   -0.06    0.45   4.98 -10.05  -3.57   0.09   3.35   9.31    123   1.01\n",
      "gamma_positive[8]   -1.17    0.44   4.89 -11.08  -4.53  -0.91   2.08   8.03    124   1.01\n",
      "gamma_positive[9]   -0.02    0.45   5.05 -10.09  -3.54   0.12   3.42   9.57    125   1.01\n",
      "gamma_positive[10]    0.2    0.45   4.98  -9.74  -3.25   0.42   3.56    9.6    124   1.01\n",
      "gamma_positive[11]  -0.82    0.44   4.89 -10.62  -4.29   -0.6   2.44   8.63    123   1.01\n",
      "gamma_positive[12]  -0.07    0.46   5.07 -10.24   -3.6   0.02   3.27   9.77    124   1.01\n",
      "gamma_positive[13]   0.04    0.45   4.98  -9.76   -3.5   0.25   3.41   9.45    123   1.01\n",
      "gamma_negative[1]    0.92    0.44   4.91  -8.79  -2.49   1.08   4.26  10.13    123   1.01\n",
      "gamma_negative[2]   -0.09    0.45   5.11 -10.25  -3.64  -0.01   3.28   9.68    130   1.01\n",
      "gamma_negative[3]    0.03    0.45   4.92  -9.85   -3.4   0.24   3.24   9.48    122   1.01\n",
      "gamma_negative[4]   -2.96    0.45   5.05 -12.94  -6.44  -3.21   0.48   6.81    126   1.01\n",
      "gamma_negative[5]    0.63    0.45   4.94  -9.19  -2.86   0.82   3.97   9.94    122   1.01\n",
      "gamma_negative[6]   -0.12    0.44    4.9 -10.12  -3.52   0.06   3.02   9.14    123   1.01\n",
      "gamma_negative[7]   -1.08    0.45   4.94  -10.9  -4.51   -1.1   2.32   8.36    123   1.01\n",
      "gamma_negative[8]   -0.83    0.44   4.91 -10.78  -4.27  -0.57   2.47    8.6    124   1.01\n",
      "gamma_negative[9]    0.11    0.45   5.15  -9.92  -3.56    0.2   3.55   9.89    129   1.01\n",
      "gamma_negative[10]  -1.63    0.45   4.97 -11.54  -5.15  -1.46   1.61   7.79    124   1.01\n",
      "gamma_negative[11]  -0.94    0.44   4.89 -10.69  -4.42  -0.92   2.29   8.45    124   1.01\n",
      "gamma_negative[12]-5.9e-3    0.45   5.14  -10.3  -3.53    0.1   3.36  10.07    131   1.01\n",
      "gamma_negative[13]   0.09    0.45   4.98  -9.63  -3.38   0.28   3.41   9.71    124   1.01\n",
      "eta_subject[1]       -0.8    0.44    4.9 -10.03  -4.15  -0.98   2.63   8.93    123   1.01\n",
      "eta_subject[2]       7.27    0.48   5.51  -3.24    3.3   7.39   11.3  17.82    132   1.01\n",
      "eta_subject[3]      -2.44    0.44    4.9 -11.87  -5.65  -2.65   0.96   7.47    121   1.01\n",
      "eta_subject[4]       3.21    0.45   5.05  -6.51  -0.28   3.46   6.64  13.15    125   1.01\n",
      "eta_subject[5]       -0.8    0.45   4.94 -10.11  -4.15  -0.98   2.71    8.9    121   1.01\n",
      "eta_subject[6]       2.39    0.44   4.88  -6.89  -0.79   2.15   5.75  12.15    123   1.01\n",
      "eta_subject[7]       3.85    0.45   4.94  -5.51    0.5   3.76   7.36  13.71    123   1.01\n",
      "eta_subject[8]      -2.25    0.44   4.88 -11.63  -5.51  -2.44   1.16   7.45    122   1.01\n",
      "eta_subject[9]        6.9    0.45    5.3   -3.4   3.41   6.55   10.7  17.49    141   1.01\n",
      "eta_subject[10]      3.36    0.45   4.97  -6.01   0.13   3.18   6.84  13.41    124   1.01\n",
      "eta_subject[11]      -2.1    0.44   4.87 -11.47  -5.39  -2.37    1.3   7.79    123   1.01\n",
      "eta_subject[12]       7.0    0.46   5.41  -3.24    3.2   6.86  10.71  17.95    135   1.01\n",
      "eta_subject[13]      3.64    0.45   4.97  -5.83   0.27   3.39   7.18  13.41    123   1.01\n",
      "theta_neutral[1]     0.57  1.5e-3   0.08   0.42   0.52   0.57   0.62   0.71   2533    1.0\n",
      "theta_neutral[2]      1.0  4.5e-5 2.4e-3   0.99    1.0    1.0    1.0    1.0   2980    1.0\n",
      "theta_neutral[3]     0.42  1.4e-3   0.07   0.27   0.37   0.42   0.47   0.56   2761    1.0\n",
      "theta_neutral[4]     0.99  3.6e-4   0.01   0.95   0.99    1.0    1.0    1.0   1280    1.0\n",
      "theta_neutral[5]     0.46  1.4e-3   0.08   0.31   0.41   0.46   0.51   0.61   3016    1.0\n",
      "theta_neutral[6]     0.99  3.2e-4   0.01   0.95   0.98   0.99    1.0    1.0   1920    1.0\n",
      "theta_neutral[7]     0.99  1.7e-4 7.4e-3   0.97   0.99    1.0    1.0    1.0   1913    1.0\n",
      "theta_neutral[8]     0.49  1.3e-3   0.08   0.34   0.44   0.49   0.54   0.64   3511    1.0\n",
      "theta_neutral[9]      1.0  5.8e-5 3.3e-3   0.99    1.0    1.0    1.0    1.0   3265    1.0\n",
      "theta_neutral[10]    0.99  1.9e-4 9.9e-3   0.97   0.99    1.0    1.0    1.0   2724    1.0\n",
      "theta_neutral[11]    0.47  1.3e-3   0.07   0.33   0.42   0.47   0.52   0.62   3492    1.0\n",
      "theta_neutral[12]     1.0  4.6e-5 2.8e-3   0.99    1.0    1.0    1.0    1.0   3559    1.0\n",
      "theta_neutral[13]    0.99  2.7e-4   0.01   0.95   0.98   0.99    1.0    1.0   2393    1.0\n",
      "theta_positive[1]    0.18  1.4e-3   0.06   0.09   0.14   0.18   0.22   0.31   1664    1.0\n",
      "theta_positive[2]     1.0  1.5e-4 8.2e-3   0.97    1.0    1.0    1.0    1.0   2873    1.0\n",
      "theta_positive[3]    0.02  5.6e-4   0.02 9.6e-4 9.5e-3   0.02   0.03   0.08   1472   1.01\n",
      "theta_positive[4]    0.98  5.7e-4   0.02   0.91   0.97   0.98   0.99    1.0   1657    1.0\n",
      "theta_positive[5]    0.31  1.5e-3   0.07   0.19   0.26   0.31   0.36   0.46   2306    1.0\n",
      "theta_positive[6]    0.77  1.1e-3   0.07   0.62   0.72   0.77   0.81   0.88   3407    1.0\n",
      "theta_positive[7]    0.97  4.3e-4   0.02   0.91   0.96   0.98   0.99    1.0   2893    1.0\n",
      "theta_positive[8]    0.04  6.6e-4   0.03 5.2e-3   0.02   0.03   0.05   0.11   1765   1.01\n",
      "theta_positive[9]     1.0  1.4e-4 7.8e-3   0.97    1.0    1.0    1.0    1.0   3255    1.0\n",
      "theta_positive[10]   0.96  2.6e-3   0.03   0.89   0.95   0.97   0.98    1.0    131   1.02\n",
      "theta_positive[11]   0.06  8.0e-4   0.03   0.01   0.03   0.05   0.08   0.14   1800    1.0\n",
      "theta_positive[12]   0.99  7.5e-4 9.4e-3   0.97   0.99    1.0    1.0    1.0    157   1.02\n",
      "theta_positive[13]   0.97  3.9e-4   0.03    0.9   0.96   0.97   0.99    1.0   4159    1.0\n",
      "theta_negative[1]    0.53  1.3e-3   0.08   0.38   0.48   0.53   0.58   0.68   3566    1.0\n",
      "theta_negative[2]     1.0  1.7e-4 8.8e-3   0.97    1.0    1.0    1.0    1.0   2789    1.0\n",
      "theta_negative[3]    0.09  9.9e-4   0.04   0.03   0.06   0.08   0.12    0.2   2017   1.01\n",
      "theta_negative[4]    0.56  1.6e-3   0.08    0.4    0.5   0.56   0.62   0.71   2363    1.0\n",
      "theta_negative[5]    0.46  1.4e-3   0.08   0.32   0.41   0.46   0.51    0.6   3120    1.0\n",
      "theta_negative[6]     0.9  7.7e-4   0.05   0.79   0.87    0.9   0.93   0.97   3507    1.0\n",
      "theta_negative[7]    0.93  7.1e-4   0.04   0.84   0.91   0.94   0.96   0.98   2780    1.0\n",
      "theta_negative[8]    0.05  1.1e-3   0.03 9.8e-3   0.03   0.05   0.07   0.14    908   1.01\n",
      "theta_negative[9]     1.0  1.4e-4 8.1e-3   0.97    1.0    1.0    1.0    1.0   3117    1.0\n",
      "theta_negative[10]   0.84  1.1e-3   0.06   0.71   0.81   0.85   0.88   0.94   2641    1.0\n",
      "theta_negative[11]   0.05  8.1e-4   0.03   0.01   0.03   0.05   0.07   0.14   1722    1.0\n",
      "theta_negative[12]    1.0  2.6e-4 8.6e-3   0.97   0.99    1.0    1.0    1.0   1068   1.01\n",
      "theta_negative[13]   0.97  5.2e-4   0.03    0.9   0.96   0.97   0.99    1.0   2382    1.0\n",
      "lp__               -461.7    0.67   9.62 -481.3 -468.1 -461.3 -455.2 -444.0    205   1.04\n",
      "\n",
      "Samples were drawn using NUTS at Fri Sep 20 09:10:35 2019.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "from pystan import StanModel\n",
    "\n",
    "\n",
    "model_input='''\n",
    "data {\n",
    "    int<lower=0> N;      // # of subjects\n",
    "    int N_cond;\n",
    "    int T_max;  // max # of trials across subjects\n",
    "    int Choice[N, N_cond, T_max]; // Choices for each subject, condition, and trial\n",
    "}\n",
    "\n",
    "parameters {  \n",
    " \n",
    "  // Parameters for group-level parameters\n",
    "  real mu_neutral;\n",
    "  real mu_positive;\n",
    "  real mu_negative;\n",
    "  real mu_subject;\n",
    "  \n",
    "  real<lower=0> sigma_neutral;\n",
    "  real<lower=0> sigma_positive;  \n",
    "  real<lower=0> sigma_negative;\n",
    "  real<lower=0> sigma_subject;\n",
    "  \n",
    "  \n",
    "  // Individual-level parameters\n",
    "  real gamma_neutral[N];\n",
    "  real gamma_positive[N];\n",
    "  real gamma_negative[N];\n",
    "  real eta_subject[N];\n",
    "}\n",
    "\n",
    "transformed parameters {\n",
    "  vector[N] theta_neutral;\n",
    "  vector[N] theta_positive;\n",
    "  vector[N] theta_negative;\n",
    "\n",
    "  // For all subjects, incorporate baseline and experimental effect, \n",
    "  // then convert to 0-1 scale via logistic function. \n",
    "  \n",
    "  for (i in 1:N) {\n",
    "    theta_neutral[i] = inv_logit(eta_subject[i]+gamma_neutral[i]);\n",
    "    theta_positive[i] = inv_logit(eta_subject[i]+gamma_positive[i]);\n",
    "    theta_negative[i] = inv_logit(eta_subject[i]+gamma_negative[i]);\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "model {\n",
    "  // Priors on group-level effects\n",
    "  mu_neutral   ~ normal(0,10);\n",
    "  mu_positive ~ normal(0,10);\n",
    "  mu_negative ~ normal(0,10);\n",
    "  mu_subject ~ normal(0,10);\n",
    "  \n",
    "  sigma_neutral ~ gamma(1,1);\n",
    "  sigma_positive ~ gamma(1,1);\n",
    "  sigma_negative ~ gamma(1,1);\n",
    "  sigma_subject ~ gamma(1,1);\n",
    "\n",
    "  \n",
    "  // Priors on individual parameters\n",
    "  gamma_neutral ~ normal(mu_neutral,sigma_neutral);\n",
    "  gamma_positive ~ normal(mu_positive,sigma_positive);\n",
    "  gamma_negative ~ normal(mu_negative,sigma_negative);\n",
    "  eta_subject ~ normal(mu_subject,sigma_subject);\n",
    "\n",
    "    \n",
    "  // Generate data for each subject via Bernoulli likelihood\n",
    "  for (i in 1:N) {\n",
    "    // Neutral condition choices\n",
    "    Choice[i,1,:] ~ bernoulli(theta_neutral[i]);\n",
    "    // Positive condition choices\n",
    "    Choice[i,2,:] ~ bernoulli(theta_positive[i]);\n",
    "    // Negative condition choices\n",
    "    Choice[i,3,:] ~ bernoulli(theta_negative[i]);    \n",
    "  }\n",
    "}\n",
    "\n",
    "'''\n",
    "data_input = {'N': 13, #subjects\n",
    "                     'N_cond': 3, # conditions\n",
    "                     'T_max': 40, # trials per condition\n",
    "                     'Choice':choice_data_3d #choice data in a 3d Vector\n",
    "                    }\n",
    "\n",
    "\n",
    "\n",
    "model_fit = StanModel(model_code=model_input)\n",
    "fit = model_fit.sampling(data=data_input)\n",
    "print(fit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
