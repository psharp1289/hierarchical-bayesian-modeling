{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to hierarchical bayes: Basics of probablity to deriving Bayes theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Conditional probabilities such as these play an important role in investigating causal questions, as we often want to compare how the probability (or, equivalently, risk) of an outcome changes under different filtering, or exposure, conditions.\" - Judea Pearl\n",
    "\n",
    "The analogy to keep with us when parsing the language of probabilities is a *frequency table.* Here, imagine we're pulling random objects out of a hat, each with a shape and color. The frequency table below lists the number of objects with a given shape and color residing in the hat. From this information, we'll explore notions of conditional probabilities, independence, probability mass and density. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blue</th>\n",
       "      <th>red</th>\n",
       "      <th>marginal (shape)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>square</th>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>circle</th>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>triangle</th>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marginal (color)</th>\n",
       "      <td>20</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  blue  red  marginal (shape)\n",
       "square              10   40                50\n",
       "circle               5   15                30\n",
       "triangle             5   25                20\n",
       "marginal (color)    20   80               100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('sample_data_class_1.csv',index_col=0)\n",
    "data #print out contigency table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p(blue|square)=?$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "blue                10\n",
       "red                 40\n",
       "marginal (shape)    50\n",
       "Name: square, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc['square']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By conditioning on square, we filter the data and only consider objects that are squares\n",
    "$p(blue|square)= 10/50 = 0.8$\n",
    "\n",
    "Now, let's assess the marginal probability of p(Blue). Note when I say marginal, I could mean a few things. The marginal is the total of all blue objects. The probability is this total divided by how many objects there are, or int this case, $p(blue)=20/100 = 0.8$\n",
    "\n",
    "Here $p(blue)=p(blue|square)$, which means that event *blue* is INDEPENDENT of  event *square*.\n",
    "\n",
    "Of note, I use the term event when a random variable is assigned to a given value. So, here, if shape and color are our two random variables, the two events are color=blue and shape=square. Alternatively, one could ask the question, are shapes independent of colors, which is at the level of random variables. Although we won't delve into it, you can see perhaps that the independence of a given color from a shape disappears when using different events. This is an indication ofan interaction between these two random variables: that the effect of conditioning on shape depends on which level of color one is considering and vice versa. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking about probability densities vs masses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability mass and density are two related but different concepts. Mass is defined as the amount of 'stuff' in a given object. Here, our objects are INTERVALS, which merely are arbitrary bins of data. Above, the data is categorical, and thus the categories define the data. But for interval-scale data, these bins could be anything. If the scale went from 0 to 100 (let's say we're talking about test scores), we could denote probability masses for each 1 point on the scale. That is, for example, $p(95)=.05$ means that 5% of the test-takers scored exactly 95% on their exam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\delta x=intervalWidth$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Mass_{total}= \\sum_{i=interval} p([x_i , x_i+\\delta x]) $ = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The point of the above equations is to formally denote that the summation of the probability mass of all intervals within a dataset must add up to 1. The interesting case we're about to see "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
